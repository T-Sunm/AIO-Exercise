{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary==1.4.5 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (1.4.5)\n",
      "Requirement already satisfied: matplotlib==3.9.3 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from matplotlib==3.9.3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\asus\\ungdung\\miniconda\\workspace\\envs\\aioex\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch-summary==1.4.5\n",
    "! pip install matplotlib==3.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "ROOT = './data'\n",
    "train_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=False,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.9\n",
    "\n",
    "len_train = int(len(train_data) * valid_ratio)\n",
    "len_valid = len(train_data) - len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = data.random_split(train_data, [len_train, len_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean  = train_data.dataset.data.float().mean() / 255\n",
    "std = train_data.dataset.data.float().std() / 255\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean, ), (std), )\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean, ), (std), )\n",
    "])\n",
    "\n",
    "train_data.dataset.transform = train_transforms\n",
    "valid_data.dataset.transform = valid_transforms\n",
    "\n",
    "batch_size = 256\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_data, \n",
    "    shuffle=True,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_data,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=5, padding='same'\n",
    "        )\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(16*4*4, 120)\n",
    "        self.linear2 = nn.Linear(120, 84)\n",
    "        self.out = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.avgpool1(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.avgpool2(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.flatten(outputs)\n",
    "        outputs = self.linear1(outputs)\n",
    "        outputs = self.linear2(outputs)\n",
    "        outputs = self.out(outputs)\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIOEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
